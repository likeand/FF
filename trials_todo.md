## 待做的实验
[ ] 1. 画picie和stego分别的mIoU，用以和swin的方法对比，验证我的说法的正确性（之前的方法确实只用了网络某些层的特征）

[ ] 2. 画resnet的各层mIoU，用以证明这种分布是具有跨网络的通用性的，而不是只在swin中存在的。

[ ] 3. cam的方法，画图阐述方法过程。

[ ] 4. 不同尺度检测的方法。阐述方法的过程。
解释使用这种方法的原因（统计不同类型物体的尺寸大小分布）。
统计所有标签中不同类别的像素占比 （像素数/包含该类别的图片数）。佐证多尺度方法的必要性。

[ ] 5. resnet， swinv2上使用cam方法和不同尺度方法的结果。

[ ] 6. linear probe 的实验，使用有标签 + freeze backbone 的训练证明融合特征的有效性。

## 待实现代码
[ ] 1. resnet和swinv2的代码

[ ] 2. 聚类的代码，并将聚类结果和标签对比

[ ] 3. cam图的方法

[ ] 4. 多尺度的方法

[ ] 5. 画图代码 包括数据的直方图和一些好的结果图（我们的方法比别的方法好的图）

[ ] 6. 使用picie的方法和stego的方法分别针对提取出的特征训练/或者说对网络训练（可以用作毕设中加工作量）。

[ ] 7. linear porbe 的有监督训练实验
## 思路
两个创新点，主要是针对发现的两个影响效果的问题，针对两个问题，得分别证明存在这样的问题。
- 问题一：不同类别需要使用的特征不同。图片中的物体需要使用更抽象的高级的特征进行分割，而图片中的背景需要使用更具体的低级的特征进行分割。
    证明存在这样的问题：比较不同特征聚类的结果。更深层的特征更倾向于为抽象的类得到更好的分割。
    提出方法解决这方面的问题：即将两种类别一定程度上区分开。使用cam图的比较高的部分作为物体部分，使用抽象的特征对这一部分进行区分。
    做实验证明这样的解决方法有效：使用cam图的方法和不使用的baseline方法相比，效果提升了。
- 问题二：一些类别占得像素比例比较少，深层的特征因为尺度原因难以得到这些类别的激活。
    证明存在这样的问题：一方面可以用cam图的实例说明，一些交通灯，交通牌等没法检测到，而图片放大后可以检测到。另一方面可以从数据的角度说明交通灯类的iou很低。
    提出方法解决这方面的问题：使用多尺度的方法检测，因为图片中有时存在跨越整个图片的物体（bus，train）也可能存在只占比很小的交通灯交通牌等。因此使用多尺度的检测方法，然后在后阶段融合。
    做实验证明这样的解决方法有效：使用多尺度融合的方法和没有使用的方法对比特征的聚类结果。